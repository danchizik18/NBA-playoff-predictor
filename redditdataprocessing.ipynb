{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb5b2550-518a-4c2e-908c-a83a61f81d36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\uma_s\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import RobertaTokenizer\n",
    "from transformers import RobertaForSequenceClassification\n",
    "from transformers import Trainer\n",
    "from transformers import TrainingArguments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83fb4890-ee05-4d15-a106-0078d30a2e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "import re\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import seaborn as sns \n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk \n",
    "from nltk.sentiment import SentimentIntensityAnalyzer as SIA\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1fd82a8e-de8a-453c-8abc-fe04048a3925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.5.1+cpu\n",
      "GPU Available: False\n",
      "Device Name: No GPU detected\n"
     ]
    }
   ],
   "source": [
    "print(\"PyTorch version:\", torch.__version__)\n",
    "print(\"GPU Available:\", torch.cuda.is_available())\n",
    "print(\"Device Name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU detected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c36692ff-cc62-4821-84d0-2c11cd6c4c8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\uma_s\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6be8bc76-7032-43db-a9b7-d0df391c139f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\uma_s\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f6559ca-1bcc-4689-ac21-20756082403d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('reddit_nba_master_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7ce15eb-0590-4aab-98ee-17081a762ad2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>ID</th>\n",
       "      <th>Author</th>\n",
       "      <th>Name</th>\n",
       "      <th>Author Flair Text</th>\n",
       "      <th># Comments</th>\n",
       "      <th>Time</th>\n",
       "      <th># Upvotes</th>\n",
       "      <th>Link</th>\n",
       "      <th>Upvote Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Daily Discussion Thread + Game Thread Index</td>\n",
       "      <td>1hybybh</td>\n",
       "      <td>NBA_MOD</td>\n",
       "      <td>t3_1hybybh</td>\n",
       "      <td>r/NBA</td>\n",
       "      <td>5</td>\n",
       "      <td>1.736536e+09</td>\n",
       "      <td>9</td>\n",
       "      <td>https://www.reddit.com/r/nba/comments/1hybybh/...</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Weekly Friday Self-Promotion and Fan Art Thread</td>\n",
       "      <td>1hy3vjo</td>\n",
       "      <td>NBA_MOD</td>\n",
       "      <td>t3_1hy3vjo</td>\n",
       "      <td>r/NBA</td>\n",
       "      <td>0</td>\n",
       "      <td>1.736514e+09</td>\n",
       "      <td>6</td>\n",
       "      <td>https://www.reddit.com/r/nba/comments/1hy3vjo/...</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jimmy Butler on his Instagram story to his Big...</td>\n",
       "      <td>1hy64xk</td>\n",
       "      <td>YujiDomainExpansion</td>\n",
       "      <td>t3_1hy64xk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1476</td>\n",
       "      <td>1.736521e+09</td>\n",
       "      <td>11827</td>\n",
       "      <td>https://streamable.com/9zqmf3</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jarrett Allen explains Ethical Basketball: \"Fa...</td>\n",
       "      <td>1hxwrre</td>\n",
       "      <td>2131andBeyond</td>\n",
       "      <td>t3_1hxwrre</td>\n",
       "      <td>:cle-5: Cavaliers</td>\n",
       "      <td>409</td>\n",
       "      <td>1.736485e+09</td>\n",
       "      <td>9988</td>\n",
       "      <td>https://streamable.com/uo94x4</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Joe Mazzulla goes in depth on what his typical...</td>\n",
       "      <td>1hxy23z</td>\n",
       "      <td>SliMShady55222</td>\n",
       "      <td>t3_1hxy23z</td>\n",
       "      <td>:sea-1: Supersonics</td>\n",
       "      <td>252</td>\n",
       "      <td>1.736490e+09</td>\n",
       "      <td>6170</td>\n",
       "      <td>https://streamable.com/u9yy46</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title       ID  \\\n",
       "0        Daily Discussion Thread + Game Thread Index  1hybybh   \n",
       "1    Weekly Friday Self-Promotion and Fan Art Thread  1hy3vjo   \n",
       "2  Jimmy Butler on his Instagram story to his Big...  1hy64xk   \n",
       "3  Jarrett Allen explains Ethical Basketball: \"Fa...  1hxwrre   \n",
       "4  Joe Mazzulla goes in depth on what his typical...  1hxy23z   \n",
       "\n",
       "                Author        Name    Author Flair Text  # Comments  \\\n",
       "0              NBA_MOD  t3_1hybybh                r/NBA           5   \n",
       "1              NBA_MOD  t3_1hy3vjo                r/NBA           0   \n",
       "2  YujiDomainExpansion  t3_1hy64xk                  NaN        1476   \n",
       "3        2131andBeyond  t3_1hxwrre    :cle-5: Cavaliers         409   \n",
       "4       SliMShady55222  t3_1hxy23z  :sea-1: Supersonics         252   \n",
       "\n",
       "           Time  # Upvotes                                               Link  \\\n",
       "0  1.736536e+09          9  https://www.reddit.com/r/nba/comments/1hybybh/...   \n",
       "1  1.736514e+09          6  https://www.reddit.com/r/nba/comments/1hy3vjo/...   \n",
       "2  1.736521e+09      11827                      https://streamable.com/9zqmf3   \n",
       "3  1.736485e+09       9988                      https://streamable.com/uo94x4   \n",
       "4  1.736490e+09       6170                      https://streamable.com/u9yy46   \n",
       "\n",
       "   Upvote Ratio  \n",
       "0          0.92  \n",
       "1          0.88  \n",
       "2          0.93  \n",
       "3          0.97  \n",
       "4          0.98  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef48f485-adcb-4b40-aa9b-cb7ae13f493d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(121766, 10)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4be2bd4d-2908-478c-941c-517387a1950b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping duplicate rows\n",
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a612177-b393-4d3e-b637-74db178ba21d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(111646, 10)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142a824e-9521-4170-a5f6-7a1a97bc1592",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb2d2f4c-3366-4d4a-9c78-0ecb27457d78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#making the title column a list to then assign sentiment labels\n",
    "title_list = df['Title'].tolist()\n",
    "type(title_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "124aff74-24b5-4fd4-847a-2b90cede4a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "sia = SIA()\n",
    "results = []\n",
    "\n",
    "for title in title_list: \n",
    "    pol_score = sia.polarity_scores(title)\n",
    "    pol_score['Title'] = title\n",
    "    results.append(pol_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "458d0f88-e94f-45dd-bbff-9b205e68de24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Title': 'Daily Discussion Thread + Game Thread Index',\n",
      "  'compound': 0.0,\n",
      "  'neg': 0.0,\n",
      "  'neu': 1.0,\n",
      "  'pos': 0.0},\n",
      " {'Title': 'Weekly Friday Self-Promotion and Fan Art Thread',\n",
      "  'compound': 0.3182,\n",
      "  'neg': 0.0,\n",
      "  'neu': 0.723,\n",
      "  'pos': 0.277},\n",
      " {'Title': 'Jimmy Butler on his Instagram story to his Big Face Coffee employee: “Our best guy '\n",
      "           'right here. You see that? See that? I gave you a compliment. That’s what bosses do. '\n",
      "           'They build you up they don’t break you down.”',\n",
      "  'compound': 0.8253,\n",
      "  'neg': 0.0,\n",
      "  'neu': 0.825,\n",
      "  'pos': 0.175}]\n"
     ]
    }
   ],
   "source": [
    "pprint(results[:3], width=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dbe28247-7705-4227-aa84-e570b987e41f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Daily Discussion Thread + Game Thread Index</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.723</td>\n",
       "      <td>0.277</td>\n",
       "      <td>0.3182</td>\n",
       "      <td>Weekly Friday Self-Promotion and Fan Art Thread</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.175</td>\n",
       "      <td>0.8253</td>\n",
       "      <td>Jimmy Butler on his Instagram story to his Big...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.577</td>\n",
       "      <td>0.423</td>\n",
       "      <td>0.7650</td>\n",
       "      <td>Jarrett Allen explains Ethical Basketball: \"Fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.848</td>\n",
       "      <td>0.152</td>\n",
       "      <td>0.3612</td>\n",
       "      <td>Joe Mazzulla goes in depth on what his typical...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   neg    neu    pos  compound  \\\n",
       "0  0.0  1.000  0.000    0.0000   \n",
       "1  0.0  0.723  0.277    0.3182   \n",
       "2  0.0  0.825  0.175    0.8253   \n",
       "3  0.0  0.577  0.423    0.7650   \n",
       "4  0.0  0.848  0.152    0.3612   \n",
       "\n",
       "                                               Title  \n",
       "0        Daily Discussion Thread + Game Thread Index  \n",
       "1    Weekly Friday Self-Promotion and Fan Art Thread  \n",
       "2  Jimmy Butler on his Instagram story to his Big...  \n",
       "3  Jarrett Allen explains Ethical Basketball: \"Fa...  \n",
       "4  Joe Mazzulla goes in depth on what his typical...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles_and_labels = pd.DataFrame.from_records(results)\n",
    "titles_and_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b4574b28-0fdb-4b17-96a3-18f4bf1e23b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(111646, 5)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles_and_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "35eea513-6ebe-4876-9357-aa5ef19696c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "      <th>Title</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Daily Discussion Thread + Game Thread Index</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.723</td>\n",
       "      <td>0.277</td>\n",
       "      <td>0.3182</td>\n",
       "      <td>Weekly Friday Self-Promotion and Fan Art Thread</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.175</td>\n",
       "      <td>0.8253</td>\n",
       "      <td>Jimmy Butler on his Instagram story to his Big...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.577</td>\n",
       "      <td>0.423</td>\n",
       "      <td>0.7650</td>\n",
       "      <td>Jarrett Allen explains Ethical Basketball: \"Fa...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.848</td>\n",
       "      <td>0.152</td>\n",
       "      <td>0.3612</td>\n",
       "      <td>Joe Mazzulla goes in depth on what his typical...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   neg    neu    pos  compound  \\\n",
       "0  0.0  1.000  0.000    0.0000   \n",
       "1  0.0  0.723  0.277    0.3182   \n",
       "2  0.0  0.825  0.175    0.8253   \n",
       "3  0.0  0.577  0.423    0.7650   \n",
       "4  0.0  0.848  0.152    0.3612   \n",
       "\n",
       "                                               Title  label  \n",
       "0        Daily Discussion Thread + Game Thread Index      1  \n",
       "1    Weekly Friday Self-Promotion and Fan Art Thread      2  \n",
       "2  Jimmy Butler on his Instagram story to his Big...      2  \n",
       "3  Jarrett Allen explains Ethical Basketball: \"Fa...      2  \n",
       "4  Joe Mazzulla goes in depth on what his typical...      2  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles_and_labels['label'] = 1 #neutral\n",
    "titles_and_labels.loc[titles_and_labels['compound'] > 0.1, 'label'] = 2 #positive\n",
    "titles_and_labels.loc[titles_and_labels['compound'] < -0.1, 'label'] = 0 #negative\n",
    "titles_and_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "635ce6e7-fcbb-4468-92ca-a379b29488ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg = titles_and_labels['neg'].tolist()\n",
    "compound = titles_and_labels['compound'].tolist()\n",
    "neu = titles_and_labels['neu'].tolist()\n",
    "pos = titles_and_labels['pos'].tolist()\n",
    "label = titles_and_labels['label'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d9bf2ccf-d924-45f0-9c29-ed375dd7ebf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['neg'] = neg\n",
    "df['neu'] = neu\n",
    "df['pos'] = pos\n",
    "df['compound'] = compound\n",
    "df['label'] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cbb7dff9-b485-40f3-9fc6-15ca16bf166d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>ID</th>\n",
       "      <th>Author</th>\n",
       "      <th>Name</th>\n",
       "      <th>Author Flair Text</th>\n",
       "      <th># Comments</th>\n",
       "      <th>Time</th>\n",
       "      <th># Upvotes</th>\n",
       "      <th>Link</th>\n",
       "      <th>Upvote Ratio</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Daily Discussion Thread + Game Thread Index</td>\n",
       "      <td>1hybybh</td>\n",
       "      <td>NBA_MOD</td>\n",
       "      <td>t3_1hybybh</td>\n",
       "      <td>r/NBA</td>\n",
       "      <td>5</td>\n",
       "      <td>1.736536e+09</td>\n",
       "      <td>9</td>\n",
       "      <td>https://www.reddit.com/r/nba/comments/1hybybh/...</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Weekly Friday Self-Promotion and Fan Art Thread</td>\n",
       "      <td>1hy3vjo</td>\n",
       "      <td>NBA_MOD</td>\n",
       "      <td>t3_1hy3vjo</td>\n",
       "      <td>r/NBA</td>\n",
       "      <td>0</td>\n",
       "      <td>1.736514e+09</td>\n",
       "      <td>6</td>\n",
       "      <td>https://www.reddit.com/r/nba/comments/1hy3vjo/...</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.723</td>\n",
       "      <td>0.277</td>\n",
       "      <td>0.3182</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jimmy Butler on his Instagram story to his Big...</td>\n",
       "      <td>1hy64xk</td>\n",
       "      <td>YujiDomainExpansion</td>\n",
       "      <td>t3_1hy64xk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1476</td>\n",
       "      <td>1.736521e+09</td>\n",
       "      <td>11827</td>\n",
       "      <td>https://streamable.com/9zqmf3</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.175</td>\n",
       "      <td>0.8253</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jarrett Allen explains Ethical Basketball: \"Fa...</td>\n",
       "      <td>1hxwrre</td>\n",
       "      <td>2131andBeyond</td>\n",
       "      <td>t3_1hxwrre</td>\n",
       "      <td>:cle-5: Cavaliers</td>\n",
       "      <td>409</td>\n",
       "      <td>1.736485e+09</td>\n",
       "      <td>9988</td>\n",
       "      <td>https://streamable.com/uo94x4</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.577</td>\n",
       "      <td>0.423</td>\n",
       "      <td>0.7650</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Joe Mazzulla goes in depth on what his typical...</td>\n",
       "      <td>1hxy23z</td>\n",
       "      <td>SliMShady55222</td>\n",
       "      <td>t3_1hxy23z</td>\n",
       "      <td>:sea-1: Supersonics</td>\n",
       "      <td>252</td>\n",
       "      <td>1.736490e+09</td>\n",
       "      <td>6170</td>\n",
       "      <td>https://streamable.com/u9yy46</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.848</td>\n",
       "      <td>0.152</td>\n",
       "      <td>0.3612</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title       ID  \\\n",
       "0        Daily Discussion Thread + Game Thread Index  1hybybh   \n",
       "1    Weekly Friday Self-Promotion and Fan Art Thread  1hy3vjo   \n",
       "2  Jimmy Butler on his Instagram story to his Big...  1hy64xk   \n",
       "3  Jarrett Allen explains Ethical Basketball: \"Fa...  1hxwrre   \n",
       "4  Joe Mazzulla goes in depth on what his typical...  1hxy23z   \n",
       "\n",
       "                Author        Name    Author Flair Text  # Comments  \\\n",
       "0              NBA_MOD  t3_1hybybh                r/NBA           5   \n",
       "1              NBA_MOD  t3_1hy3vjo                r/NBA           0   \n",
       "2  YujiDomainExpansion  t3_1hy64xk                  NaN        1476   \n",
       "3        2131andBeyond  t3_1hxwrre    :cle-5: Cavaliers         409   \n",
       "4       SliMShady55222  t3_1hxy23z  :sea-1: Supersonics         252   \n",
       "\n",
       "           Time  # Upvotes                                               Link  \\\n",
       "0  1.736536e+09          9  https://www.reddit.com/r/nba/comments/1hybybh/...   \n",
       "1  1.736514e+09          6  https://www.reddit.com/r/nba/comments/1hy3vjo/...   \n",
       "2  1.736521e+09      11827                      https://streamable.com/9zqmf3   \n",
       "3  1.736485e+09       9988                      https://streamable.com/uo94x4   \n",
       "4  1.736490e+09       6170                      https://streamable.com/u9yy46   \n",
       "\n",
       "   Upvote Ratio  neg    neu    pos  compound  label  \n",
       "0          0.92  0.0  1.000  0.000    0.0000      1  \n",
       "1          0.88  0.0  0.723  0.277    0.3182      2  \n",
       "2          0.93  0.0  0.825  0.175    0.8253      2  \n",
       "3          0.97  0.0  0.577  0.423    0.7650      2  \n",
       "4          0.98  0.0  0.848  0.152    0.3612      2  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1ce54784-f590-4801-9fd1-153ddc579dff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34636</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0  count\n",
       "label       \n",
       "0      19947\n",
       "1      57063\n",
       "2      34636"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(index=df[\"label\"], columns=\"count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "139c72c1-68bb-4a1d-b81c-4903a14af1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove Irrelevant Characters\n",
    "def remove_irrelevant_characters(text):\n",
    "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", \"\", text)  # Remove URLs\n",
    "    text = re.sub(r\"<.*?>\", \"\", text)  # Remove HTML tags\n",
    "    text = re.sub(r\"[^a-zA-Z\\s]\", \"\", text)  # Remove special characters\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a4973c7a-1162-4f9e-b441-2ec099bcd901",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert Text to Lowercase\n",
    "def to_lowercase(text):\n",
    "    return text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7304770d-0c6b-4f00-a2fe-be90aa527dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove Stop Words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    words = text.split()\n",
    "    filtered_words = [word for word in words if word not in stop_words]\n",
    "    return \" \".join(filtered_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e01e23f3-eb93-4088-90b8-840225e4acfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stemming \n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def stem_words(text):\n",
    "    words = text.split()\n",
    "    stemmed_words = [stemmer.stem(word) for word in words]\n",
    "    return \" \".join(stemmed_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ec4394aa-e036-4cdb-b768-809d58043bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Whitespace Normalization\n",
    "def normalize_whitespace(text):\n",
    "    return \" \".join(text.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e0e1f153-5d0a-4147-a182-a6c7fe79bc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#all functions in a pipelineabs\n",
    "def clean_text_pipeline(text):\n",
    "    text = remove_irrelevant_characters(text)\n",
    "    text = to_lowercase(text)\n",
    "    text = remove_stopwords(text)\n",
    "    text = normalize_whitespace(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "456c3a44-cc33-4c2c-b3aa-1c3e8709c836",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Cleaned Titles\"] = df[\"Title\"].apply(clean_text_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "020e28ac-cd54-47f1-9a66-b1e117836f00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>ID</th>\n",
       "      <th>Author</th>\n",
       "      <th>Name</th>\n",
       "      <th>Author Flair Text</th>\n",
       "      <th># Comments</th>\n",
       "      <th>Time</th>\n",
       "      <th># Upvotes</th>\n",
       "      <th>Link</th>\n",
       "      <th>Upvote Ratio</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "      <th>label</th>\n",
       "      <th>Cleaned Titles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Daily Discussion Thread + Game Thread Index</td>\n",
       "      <td>1hybybh</td>\n",
       "      <td>NBA_MOD</td>\n",
       "      <td>t3_1hybybh</td>\n",
       "      <td>r/NBA</td>\n",
       "      <td>5</td>\n",
       "      <td>1.736536e+09</td>\n",
       "      <td>9</td>\n",
       "      <td>https://www.reddit.com/r/nba/comments/1hybybh/...</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>daily discussion thread game thread index</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Weekly Friday Self-Promotion and Fan Art Thread</td>\n",
       "      <td>1hy3vjo</td>\n",
       "      <td>NBA_MOD</td>\n",
       "      <td>t3_1hy3vjo</td>\n",
       "      <td>r/NBA</td>\n",
       "      <td>0</td>\n",
       "      <td>1.736514e+09</td>\n",
       "      <td>6</td>\n",
       "      <td>https://www.reddit.com/r/nba/comments/1hy3vjo/...</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.723</td>\n",
       "      <td>0.277</td>\n",
       "      <td>0.3182</td>\n",
       "      <td>2</td>\n",
       "      <td>weekly friday selfpromotion fan art thread</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jimmy Butler on his Instagram story to his Big...</td>\n",
       "      <td>1hy64xk</td>\n",
       "      <td>YujiDomainExpansion</td>\n",
       "      <td>t3_1hy64xk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1476</td>\n",
       "      <td>1.736521e+09</td>\n",
       "      <td>11827</td>\n",
       "      <td>https://streamable.com/9zqmf3</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.175</td>\n",
       "      <td>0.8253</td>\n",
       "      <td>2</td>\n",
       "      <td>jimmy butler instagram story big face coffee e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jarrett Allen explains Ethical Basketball: \"Fa...</td>\n",
       "      <td>1hxwrre</td>\n",
       "      <td>2131andBeyond</td>\n",
       "      <td>t3_1hxwrre</td>\n",
       "      <td>:cle-5: Cavaliers</td>\n",
       "      <td>409</td>\n",
       "      <td>1.736485e+09</td>\n",
       "      <td>9988</td>\n",
       "      <td>https://streamable.com/uo94x4</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.577</td>\n",
       "      <td>0.423</td>\n",
       "      <td>0.7650</td>\n",
       "      <td>2</td>\n",
       "      <td>jarrett allen explains ethical basketball farm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Joe Mazzulla goes in depth on what his typical...</td>\n",
       "      <td>1hxy23z</td>\n",
       "      <td>SliMShady55222</td>\n",
       "      <td>t3_1hxy23z</td>\n",
       "      <td>:sea-1: Supersonics</td>\n",
       "      <td>252</td>\n",
       "      <td>1.736490e+09</td>\n",
       "      <td>6170</td>\n",
       "      <td>https://streamable.com/u9yy46</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.848</td>\n",
       "      <td>0.152</td>\n",
       "      <td>0.3612</td>\n",
       "      <td>2</td>\n",
       "      <td>joe mazzulla goes depth typical conversations ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121757</th>\n",
       "      <td>Oblique strains are far less common in the NBA...</td>\n",
       "      <td>1ggogh5</td>\n",
       "      <td>ILikeDillonBrooks</td>\n",
       "      <td>t3_1ggogh5</td>\n",
       "      <td>DPSF</td>\n",
       "      <td>5</td>\n",
       "      <td>1.730407e+09</td>\n",
       "      <td>23</td>\n",
       "      <td>https://x.com/instreetclothes/status/185205816...</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.199</td>\n",
       "      <td>0.801</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.6908</td>\n",
       "      <td>0</td>\n",
       "      <td>oblique strains far less common nba sports par...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121758</th>\n",
       "      <td>Bane and Smart out</td>\n",
       "      <td>1ggkx6z</td>\n",
       "      <td>Altruistic_Brief4444</td>\n",
       "      <td>t3_1ggkx6z</td>\n",
       "      <td>DB</td>\n",
       "      <td>46</td>\n",
       "      <td>1.730398e+09</td>\n",
       "      <td>36</td>\n",
       "      <td>https://i.redd.it/89eprmzlt4yd1.jpeg</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.526</td>\n",
       "      <td>0.474</td>\n",
       "      <td>0.4019</td>\n",
       "      <td>2</td>\n",
       "      <td>bane smart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121761</th>\n",
       "      <td>HAPPY JALLOWEEN!! Will it be Trick or Treat fo...</td>\n",
       "      <td>1ggeap3</td>\n",
       "      <td>nam67</td>\n",
       "      <td>t3_1ggeap3</td>\n",
       "      <td>HUFF DADDY</td>\n",
       "      <td>90</td>\n",
       "      <td>1.730381e+09</td>\n",
       "      <td>37</td>\n",
       "      <td>https://www.reddit.com/r/memphisgrizzlies/comm...</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.669</td>\n",
       "      <td>0.287</td>\n",
       "      <td>0.8185</td>\n",
       "      <td>2</td>\n",
       "      <td>happy jalloween trick treat memphis tonight gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121762</th>\n",
       "      <td>Dicks Sporting Goods has some 23/24 city editi...</td>\n",
       "      <td>1gghtyv</td>\n",
       "      <td>liltrikz</td>\n",
       "      <td>t3_1gghtyv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>1.730390e+09</td>\n",
       "      <td>18</td>\n",
       "      <td>https://i.redd.it/s50g97tv54yd1.jpeg</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.893</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.3400</td>\n",
       "      <td>2</td>\n",
       "      <td>dicks sporting goods city edition gear sale ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121764</th>\n",
       "      <td>2 tickets if anyone is interested</td>\n",
       "      <td>1ggqln6</td>\n",
       "      <td>Waggledaddy</td>\n",
       "      <td>t3_1ggqln6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1.730413e+09</td>\n",
       "      <td>4</td>\n",
       "      <td>https://www.reddit.com/gallery/1ggqln6</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.597</td>\n",
       "      <td>0.403</td>\n",
       "      <td>0.4019</td>\n",
       "      <td>2</td>\n",
       "      <td>tickets anyone interested</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>111646 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Title       ID  \\\n",
       "0             Daily Discussion Thread + Game Thread Index  1hybybh   \n",
       "1         Weekly Friday Self-Promotion and Fan Art Thread  1hy3vjo   \n",
       "2       Jimmy Butler on his Instagram story to his Big...  1hy64xk   \n",
       "3       Jarrett Allen explains Ethical Basketball: \"Fa...  1hxwrre   \n",
       "4       Joe Mazzulla goes in depth on what his typical...  1hxy23z   \n",
       "...                                                   ...      ...   \n",
       "121757  Oblique strains are far less common in the NBA...  1ggogh5   \n",
       "121758                                 Bane and Smart out  1ggkx6z   \n",
       "121761  HAPPY JALLOWEEN!! Will it be Trick or Treat fo...  1ggeap3   \n",
       "121762  Dicks Sporting Goods has some 23/24 city editi...  1gghtyv   \n",
       "121764                  2 tickets if anyone is interested  1ggqln6   \n",
       "\n",
       "                      Author        Name    Author Flair Text  # Comments  \\\n",
       "0                    NBA_MOD  t3_1hybybh                r/NBA           5   \n",
       "1                    NBA_MOD  t3_1hy3vjo                r/NBA           0   \n",
       "2        YujiDomainExpansion  t3_1hy64xk                  NaN        1476   \n",
       "3              2131andBeyond  t3_1hxwrre    :cle-5: Cavaliers         409   \n",
       "4             SliMShady55222  t3_1hxy23z  :sea-1: Supersonics         252   \n",
       "...                      ...         ...                  ...         ...   \n",
       "121757     ILikeDillonBrooks  t3_1ggogh5                 DPSF           5   \n",
       "121758  Altruistic_Brief4444  t3_1ggkx6z                   DB          46   \n",
       "121761                 nam67  t3_1ggeap3           HUFF DADDY          90   \n",
       "121762              liltrikz  t3_1gghtyv                  NaN           7   \n",
       "121764           Waggledaddy  t3_1ggqln6                  NaN           0   \n",
       "\n",
       "                Time  # Upvotes  \\\n",
       "0       1.736536e+09          9   \n",
       "1       1.736514e+09          6   \n",
       "2       1.736521e+09      11827   \n",
       "3       1.736485e+09       9988   \n",
       "4       1.736490e+09       6170   \n",
       "...              ...        ...   \n",
       "121757  1.730407e+09         23   \n",
       "121758  1.730398e+09         36   \n",
       "121761  1.730381e+09         37   \n",
       "121762  1.730390e+09         18   \n",
       "121764  1.730413e+09          4   \n",
       "\n",
       "                                                     Link  Upvote Ratio  \\\n",
       "0       https://www.reddit.com/r/nba/comments/1hybybh/...          0.92   \n",
       "1       https://www.reddit.com/r/nba/comments/1hy3vjo/...          0.88   \n",
       "2                           https://streamable.com/9zqmf3          0.93   \n",
       "3                           https://streamable.com/uo94x4          0.97   \n",
       "4                           https://streamable.com/u9yy46          0.98   \n",
       "...                                                   ...           ...   \n",
       "121757  https://x.com/instreetclothes/status/185205816...          0.96   \n",
       "121758               https://i.redd.it/89eprmzlt4yd1.jpeg          0.97   \n",
       "121761  https://www.reddit.com/r/memphisgrizzlies/comm...          0.98   \n",
       "121762               https://i.redd.it/s50g97tv54yd1.jpeg          0.96   \n",
       "121764             https://www.reddit.com/gallery/1ggqln6          0.84   \n",
       "\n",
       "          neg    neu    pos  compound  label  \\\n",
       "0       0.000  1.000  0.000    0.0000      1   \n",
       "1       0.000  0.723  0.277    0.3182      2   \n",
       "2       0.000  0.825  0.175    0.8253      2   \n",
       "3       0.000  0.577  0.423    0.7650      2   \n",
       "4       0.000  0.848  0.152    0.3612      2   \n",
       "...       ...    ...    ...       ...    ...   \n",
       "121757  0.199  0.801  0.000   -0.6908      0   \n",
       "121758  0.000  0.526  0.474    0.4019      2   \n",
       "121761  0.045  0.669  0.287    0.8185      2   \n",
       "121762  0.000  0.893  0.107    0.3400      2   \n",
       "121764  0.000  0.597  0.403    0.4019      2   \n",
       "\n",
       "                                           Cleaned Titles  \n",
       "0               daily discussion thread game thread index  \n",
       "1              weekly friday selfpromotion fan art thread  \n",
       "2       jimmy butler instagram story big face coffee e...  \n",
       "3       jarrett allen explains ethical basketball farm...  \n",
       "4       joe mazzulla goes depth typical conversations ...  \n",
       "...                                                   ...  \n",
       "121757  oblique strains far less common nba sports par...  \n",
       "121758                                         bane smart  \n",
       "121761  happy jalloween trick treat memphis tonight gr...  \n",
       "121762  dicks sporting goods city edition gear sale ha...  \n",
       "121764                          tickets anyone interested  \n",
       "\n",
       "[111646 rows x 16 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "373d8772-fe9c-4645-9329-ce1aeb2a238c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting dataset\n",
    "\n",
    "train_texts, temp_texts, train_labels, temp_labels = train_test_split(\n",
    "    df[\"Cleaned Titles\"], df[\"label\"], test_size=0.3, random_state=42)\n",
    "val_texts, test_texts, val_labels, test_labels = train_test_split(\n",
    "    temp_texts, temp_labels, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f9ba5d90-852b-415e-af6c-47dfa49af837",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenization\n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "def tokenize_data(texts, labels):\n",
    "    tokenized_inputs = tokenizer(\n",
    "        texts.tolist(),\n",
    "        truncation=True,\n",
    "        padding=True,\n",
    "        max_length=512,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    tokenized_inputs[\"labels\"] = torch.tensor(labels.tolist())\n",
    "    return tokenized_inputs\n",
    "\n",
    "train_data = tokenize_data(train_texts, train_labels)\n",
    "val_data = tokenize_data(val_texts, val_labels)\n",
    "test_data = tokenize_data(test_texts, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1b9a87f4-9e87-4d29-8695-76c431262dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparing the dataset class \n",
    "class RedditDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings[\"input_ids\"])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {key: tensor[idx] for key, tensor in self.encodings.items()}\n",
    "\n",
    "train_dataset = RedditDataset(train_data)\n",
    "val_dataset = RedditDataset(val_data)\n",
    "test_dataset = RedditDataset(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "508f84e8-ff66-46b1-88db-c6ae51877e59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Define and Fine-Tune the Model \n",
    "\n",
    "model = RobertaForSequenceClassification.from_pretrained(\"roberta-base\", num_labels=3) \n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    eval_strategy=\"steps\",\n",
    "    save_strategy=\"steps\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=2,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    #eval_steps = 1000, \n",
    "    #save_steps = 1000, \n",
    "    load_best_model_at_end=True\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ef9f8d44-96cf-4195-bfe4-27a302b4f71e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='7329' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [   8/7329 00:42 < 14:32:40, 0.14 it/s, Epoch 0.00/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtrain()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\trainer.py:2171\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   2169\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[0;32m   2170\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2171\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m inner_training_loop(\n\u001b[0;32m   2172\u001b[0m         args\u001b[38;5;241m=\u001b[39margs,\n\u001b[0;32m   2173\u001b[0m         resume_from_checkpoint\u001b[38;5;241m=\u001b[39mresume_from_checkpoint,\n\u001b[0;32m   2174\u001b[0m         trial\u001b[38;5;241m=\u001b[39mtrial,\n\u001b[0;32m   2175\u001b[0m         ignore_keys_for_eval\u001b[38;5;241m=\u001b[39mignore_keys_for_eval,\n\u001b[0;32m   2176\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\trainer.py:2531\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   2524\u001b[0m context \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   2525\u001b[0m     functools\u001b[38;5;241m.\u001b[39mpartial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mno_sync, model\u001b[38;5;241m=\u001b[39mmodel)\n\u001b[0;32m   2526\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch_samples) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   2527\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m!=\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mDEEPSPEED\n\u001b[0;32m   2528\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39mnullcontext\n\u001b[0;32m   2529\u001b[0m )\n\u001b[0;32m   2530\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[1;32m-> 2531\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_step(model, inputs, num_items_in_batch)\n\u001b[0;32m   2533\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   2534\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[0;32m   2535\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[0;32m   2536\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[0;32m   2537\u001b[0m ):\n\u001b[0;32m   2538\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[0;32m   2539\u001b[0m     tr_loss \u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m+\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\trainer.py:3715\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   3712\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_items_in_batch \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3713\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mgradient_accumulation_steps\n\u001b[1;32m-> 3715\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mbackward(loss, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   3717\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\u001b[38;5;241m.\u001b[39mdetach()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\accelerate\\accelerator.py:2248\u001b[0m, in \u001b[0;36mAccelerator.backward\u001b[1;34m(self, loss, **kwargs)\u001b[0m\n\u001b[0;32m   2246\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlomo_backward(loss, learning_rate)\n\u001b[0;32m   2247\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2248\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    580\u001b[0m     )\n\u001b[1;32m--> 581\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[0;32m    582\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[0;32m    583\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\autograd\\__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 347\u001b[0m _engine_run_backward(\n\u001b[0;32m    348\u001b[0m     tensors,\n\u001b[0;32m    349\u001b[0m     grad_tensors_,\n\u001b[0;32m    350\u001b[0m     retain_graph,\n\u001b[0;32m    351\u001b[0m     create_graph,\n\u001b[0;32m    352\u001b[0m     inputs,\n\u001b[0;32m    353\u001b[0m     allow_unreachable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    354\u001b[0m     accumulate_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    355\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\autograd\\graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    826\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    827\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1496262b-1e64-4ff2-a617-1c9216bd0331",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010c7e55-f406-4c1f-a92e-9cdb7b048f12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0678b077-ea92-4c98-afe3-fde210780985",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1814429e-a796-4342-b652-faa9aae161c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e81b3e-4f0e-492b-b105-117d8d1b2519",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f38936a-9eb4-45ec-97cd-24111a7efa7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9772a8-9cd7-4a92-8d33-bd7e4a91d341",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
